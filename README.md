# üìß Spam Detection Using Logistic Regression, Decision Tree, and TF-IDF

## üìÄ Overview
Spam messages and emails pose a significant challenge in maintaining communication efficiency and data security. This project addresses the problem by building a **robust spam detection framework** that combines **TF-IDF** feature extraction with **Logistic Regression** and **Decision Tree Classifiers**. 

To evaluate the effectiveness and generalizability of the framework, experiments are conducted on two datasets: **SMS Spam Collection** and **Enron Spam Dataset**. The project delivers key insights into model performance, cross-dataset generalization, and visualizations, achieving high accuracy while paving the way for future advancements.


---

## üöÄ Key Features
- **Advanced Text Preprocessing**:
  - Lowercasing
  - Tokenization
  - Stop-word removal
  - Punctuation removal
- **TF-IDF Vectorization**:
  - Converts raw text into meaningful numerical features that represent word importance within the dataset.
- **Classification Models**:
  - **Logistic Regression** for establishing a baseline.
  - **Decision Tree Classifier** with hyperparameter tuning for improved performance.
- **Cross-Dataset Generalization**:
  - Trains on one dataset (e.g., Enron) and evaluates on another (e.g., SMS Spam Collection) to test robustness.
- **Comprehensive Evaluation**:
  - Metrics: Confusion Matrix, Classification Report, Accuracy.
- **Visualizations**:
  - Heatmaps for confusion matrices.
  - Bar plots comparing accuracy across models and datasets.
  - Graphs demonstrating the relationship between tree depth and classification accuracy.

---

## üìÉ Datasets
### 1. **SMS Spam Collection**:
- **Overview**: A widely recognized dataset containing labeled SMS messages as spam or ham.
- **Statistics**:
  - Total messages: 5,574
  - Spam: 13.4%
  - Ham (non-spam): 86.6%
- üîó [Download Link](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)

### 2. **Enron Spam Dataset**:
- **Overview**: A large dataset containing email messages labeled as spam or ham, suitable for email spam detection.
- **Statistics**:
  - Total messages: 33,716
  - Approx. Spam: 50%
- üîó [Download Link](https://github.com/MWiechmann/enron_spam_data?tab=readme-ov-file)

üìÅ **Instructions**: Save both datasets in the `dataset/` directory of the project.

---

## üìö Methodology
### 1. **Text Preprocessing**:
   - **Lowercasing**: Ensures uniformity by converting all text to lowercase.
   - **Tokenization**: Breaks sentences into individual words.
   - **Stop-word Removal**: Removes common but irrelevant words (e.g., "and," "the").
   - **Punctuation Removal**: Cleans special characters to focus on meaningful words.
### 2. **Feature Extraction**:
   - **TF-IDF Vectorization**:
     - Assigns a weight to each word based on its importance in the message and across the dataset.
     - Captures both term frequency (importance within a message) and inverse document frequency (rarity across the dataset).
### 3. **Classification Models**:
   - **Logistic Regression**:
     - A linear model for establishing baseline performance.
     - Efficient and interpretable.
   - **Decision Tree Classifier**:
     - A non-parametric model tuned for depth and split criteria using **Grid Search**.
     - Balances underfitting and overfitting by analyzing tree depth.
### 4. **Cross-Dataset Evaluation**:
   - Trains on one dataset (e.g., Enron) and evaluates on another (e.g., SMS Spam Collection) to assess generalizability.

---

## ‚öôÔ∏è Requirements
Install the necessary Python libraries using:
```bash
pip install -r requirements.txt
```

### Dependencies
- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`
- `seaborn`
- `nltk`

---

## üóÇ Project Structure
- **`notebook.ipynb`**: Contains code implementation and detailed analysis.
- **`dataset/`**: Directory for datasets.
- **`README.md`**: Project documentation.
- **`requirements.txt`**: List of dependencies for easy installation.
- **`images/`**: Stores visualizations generated by the notebook.
- **`docs/`**: Additional documentation, including a research paper.
- **`.gitignore`**: Excludes unnecessary files from version control.

---

## üîß How to Use
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/saberfazliahmadi/spam-detection-tfidf.git
   cd spam-detection-tfidf
   ```
2. **Download Datasets**: Save the datasets in the `dataset/` folder.
3. **Run Notebook**:
   - Launch Jupyter Notebook:
     ```bash
     jupyter notebook
     ```
   - Open `notebook.ipynb` and execute cells to:
     - Preprocess data.
     - Train and evaluate models.
     - Visualize results.

---

## üìä Results
### Key Findings:
1. **Logistic Regression**:
   - **SMS Spam Collection Accuracy**: 96.50%
   - **Enron Dataset Accuracy**: 95.20%
2. **Decision Tree Classifier**:
   - **SMS Spam Collection Accuracy**: 95.90%
   - **Enron Dataset Accuracy**: 94.80%
3. **Cross-Dataset Evaluation**:
   - Training on Enron and testing on SMS Spam Collection achieves an accuracy of **93.75%**, showcasing strong generalizability.

---

## üìà Visual Insights
### Examples of Visualizations:
1. **Confusion Matrix - Enron Dataset**:
   ![Confusion Matrix](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/images/confusion_matrix_enron.png)
2. **Accuracy Comparison Across Models**:
   ![Accuracy Comparison](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/images/accuracy_comparison.png)
   
   ![Effects of 3 depth on Accuracy Comparison 1_20](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/images/Tree_Depth_vs_Accuracy.jpg)
4. **Effect of Tree Depth on Accuracy**:
   ![Tree Depth Impact](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/images/Effect_of_Tree_Depth_on_Accuracy.png)

   ![1_100 Depth Impact](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/images/Effect_of_Tree_Depth_on_Accuracy_1_100.jpg)

---

## üåü Future Work
- **Model Enhancements**:
  - Experiment with Random Forest, Support Vector Machines (SVM), and Transformers like BERT.
  - Explore ensemble methods for improved accuracy.
- **Feature Extraction Improvements**:
  - Leverage advanced embeddings like Word2Vec, GloVe, or Sentence-BERT.
- **Scalability**:
  - Apply the framework to larger datasets and real-world spam detection systems.

---

## üìÑ License
This project is licensed under the **MIT License**. See the LICENSE file for details.

---

## üîñ Research Paper
A detailed research paper elaborating on the methodology and findings is available:  
[Spam Detection Using TF-IDF and Decision Tree](https://github.com/saberfazliahmadi/spam-detection-tfidf/blob/main/docs/Spam_Detection_Paper.md)

---

## üñêÔ∏è Authors
- **[Saber Fazliahmadi](https://github.com/saberfazliahmadi)**
- **Muhammad Usman Hussain**

